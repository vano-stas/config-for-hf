version: 1.2.4

cache: true

interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true

registration:
  socialLogins:
    - "discord"
    - "facebook"
    - "github"
    - "google"
    - "openid"

endpoints:
  custom:
    # deepseek
    # https://platform.deepseek.com/api_keys
    # Model list: https://platform.deepseek.com/api-docs/pricing
    - name: "deepseek"
      apiKey: "user_provided"
      baseURL: "https://api.deepseek.com"
      models:
        default:
          - deepseek-chat
          - deepseek-reasoner
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      modelDisplayLabel: "DeepSeek"

    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "user_provided"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default:
          - allam-2-7b
          - compound-beta
          - compound-beta-mini
          - deepseek-r1-distill-llama-70b
          - gemma2-9b-it
          - llama-3.1-8b-instant
          - llama-3.3-70b-versatile
          - llama-guard-3-8b
          - llama3-70b-8192
          - llama3-8b-8192
          - meta-llama/llama-4-maverick-17b-128e-instruct
          - meta-llama/llama-4-scout-17b-16e-instruct
          - meta-llama/llama-guard-4-12b
          - mistral-saba-24b
          - playai-tts
          - playai-tts-arabic
          - qwen-qwq-32b
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"

    # HuggingFace
    # https://huggingface.co/settings/tokens
    - name: 'HuggingFace'
      apiKey: 'user_provided'
      baseURL: 'https://api-inference.huggingface.co/v1'
      models:
        default:
          - AIDC-AI/Marco-o1
          - CohereLabs/c4ai-command-r-plus
          - CohereLabs/c4ai-command-r-v01
          - HuggingFaceH4/zephyr-7b-alpha
          - HuggingFaceH4/zephyr-7b-beta
          - HuggingFaceTB/SmolLM2-1.7B-Instruct
          - Intel/neural-chat-7b-v3-1
          - MiniMaxAI/MiniMax-Text-01
          - NexaAIDev/Octopus-v2
          - Open-Orca/Mistral-7B-OpenOrca
          - PygmalionAI/pygmalion-6b
          - Qwen/QwQ-32B
          - Qwen/QwQ-32B-Preview
          - Qwen/Qwen2-72B-Instruct
          - Qwen/Qwen2-7B-Instruct
          - Qwen/Qwen2.5-72B-Instruct
          - Qwen/Qwen2.5-7B-Instruct
          - Qwen/Qwen2.5-Coder-32B-Instruct
          - Qwen/Qwen3-235B-A22B
          - Qwen/Qwen3-30B-A3B
          - TinyLlama/TinyLlama-1.1B-Chat-v1.0
          - agentica-org/DeepCoder-14B-Preview
          - berkeley-nest/Starling-LM-7B-alpha
          - cognitivecomputations/dolphin-2.5-mixtral-8x7b
          - databricks/dbrx-base
          - databricks/dbrx-instruct
          - deepseek-ai/DeepSeek-Coder-V2-Instruct
          - deepseek-ai/DeepSeek-Prover-V2-671B
          - deepseek-ai/DeepSeek-R1
          - deepseek-ai/DeepSeek-R1-Distill-Llama-70B
          - deepseek-ai/DeepSeek-R1-Distill-Llama-8B
          - deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
          - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
          - deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
          - deepseek-ai/DeepSeek-R1-Zero
          - deepseek-ai/DeepSeek-V2.5
          - deepseek-ai/DeepSeek-V3
          - deepseek-ai/DeepSeek-V3-0324
          - google/gemma-2-2b-it
          - google/gemma-2-9b-it
          - google/gemma-2b-it
          - google/gemma-7b-it
          - gradientai/Llama-3-8B-Instruct-Gradient-1048k
          - jinaai/ReaderLM-v2
          - jinaai/reader-lm-1.5b
          - manycore-research/SpatialLM-Llama-1B
          - mattshumer/Reflection-Llama-3.1-70B
          - meta-llama/Llama-2-13b-chat-hf
          - meta-llama/Llama-2-70b-chat-hf
          - meta-llama/Llama-2-7b-chat-hf
          - meta-llama/Llama-3.1-405B-Instruct
          - meta-llama/Llama-3.1-70B-Instruct
          - meta-llama/Llama-3.1-8B-Instruct
          - meta-llama/Llama-3.2-1B-Instruct
          - meta-llama/Llama-3.2-3B-Instruct
          - meta-llama/Llama-3.3-70B-Instruct
          - meta-llama/Meta-Llama-3-70B-Instruct
          - meta-llama/Meta-Llama-3-8B-Instruct
          - microsoft/Phi-3-mini-128k-instruct
          - microsoft/Phi-3-mini-4k-instruct
          - microsoft/Phi-3-vision-128k-instruct
          - microsoft/Phi-3.5-MoE-instruct
          - microsoft/Phi-3.5-mini-instruct
          - microsoft/bitnet-b1.58-2B-4T
          - microsoft/phi-4
          - mistralai/Codestral-22B-v0.1
          - mistralai/Mistral-7B-Instruct-v0.1
          - mistralai/Mistral-7B-Instruct-v0.2
          - mistralai/Mistral-7B-Instruct-v0.3
          - mistralai/Mistral-Nemo-Instruct-2407
          - mistralai/Mistral-Small-24B-Instruct-2501
          - mistralai/Mixtral-8x22B-Instruct-v0.1
          - mistralai/Mixtral-8x7B-Instruct-v0.1
          - nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
          - nvidia/Llama3-ChatQA-1.5-8B
          - openchat/openchat_3.5
          - perplexity-ai/r1-1776
          - shenzhi-wang/Llama3-8B-Chinese-Chat
          - teknium/OpenHermes-2.5-Mistral-7B
          - tiiuae/falcon-180B-chat
          - tiiuae/falcon-7b-instruct
          - unsloth/DeepSeek-R1-GGUF
          - upstage/SOLAR-10.7B-Instruct-v1.0
        fetch: false
      titleConvo: true
      titleModel: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
      dropParams:
        - "top_p"

    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default:
          - openrouter/auto
          - google/gemini-2.5-flash-lite
          - google/gemini-2.5-flash
          - moonshotai/kimi-k2
          - openai/codex-mini
          - openai/gpt-4.1
          - openai/gpt-4.1-mini
          - openai/gpt-4.1-nano
          - openai/gpt-4o-mini
          - qwen/qwen3-coder
          - '---FREE---'
          - qwen/qwen-2.5-72b-instruct:free
          - qwen/qwen-2.5-7b-instruct:free
          - qwen/qwen-2.5-coder-32b-instruct:free
          - qwen/qwen3-14b:free
          - qwen/qwen3-235b-a22b:free
          - qwen/qwen3-32b:free
          - '---ANTHROPIC---'
          - anthropic/claude-3.7-sonnet
          - anthropic/claude-3.7-sonnet:thinking
          - anthropic/claude-opus-4
          - anthropic/claude-sonnet-4
          - '---DEEPSEEK---'
          - deepseek/deepseek-chat
          - deepseek/deepseek-chat-v3-0324
          - deepseek/deepseek-coder
          - deepseek/deepseek-prover-v2
          - deepseek/deepseek-r1
          - deepseek/deepseek-r1-distill-llama-70b
          - deepseek/deepseek-r1-distill-llama-8b
          - deepseek/deepseek-r1-distill-qwen-1.5b
          - deepseek/deepseek-r1-distill-qwen-14b
          - deepseek/deepseek-r1-distill-qwen-32b
          - '---GOOGLE---'
          - google/gemini-2.5-pro
          - google/gemini-2.5-pro-preview
          - '---QWEN---'
          - qwen/qwen3-coder:free
          - qwen/qwen3-coder
          - qwen/qwen3-235b-a22b-2507
          - qwen/qwen-2-72b-instruct
          - qwen/qwen-2.5-72b-instruct
          - qwen/qwen-2.5-7b-instruct
          - qwen/qwen-2.5-coder-32b-instruct
          - qwen/qwen3-235b-a22b
          - qwen/qwen3-30b-a3b
          - qwen/qwen3-32b
          - qwen/qwen3-8b
        fetch: true
      dropParams:
        - "stop"
      titleConvo: true
      titleModel: "openai/gpt-4o-mini"
      summarize: false
      summaryModel: "openai/gpt-4o-mini"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "user_provided"
      baseURL: "https://api.perplexity.ai/"
      models:
        default:
          - r1-1776
          - sonar
          - sonar-deep-research
          - sonar-pro
          - sonar-reasoning
          - sonar-reasoning-pro
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "sonar"
      forcePrompt: false
      dropParams:
        - "stop"
        - "frequency_penalty"
      modelDisplayLabel: "Perplexity"

    # xAI
    # https://x.ai/api
    - name: "xai"
      apiKey: "user_provided"
      baseURL: "https://api.x.ai/v1"
      models:
        default:
          - grok-2-1212
          - grok-2-vision-1212
          - grok-3-beta
          - grok-3-mini-beta
          - grok-beta
          - grok-vision-beta
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "grok-beta"
      summarize: false
      summaryModel: "grok-beta"
      forcePrompt: false
      modelDisplayLabel: "Grok"
